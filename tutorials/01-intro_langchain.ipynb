{
 "cells": [
  {
   "cell_type": "code",
   "id": "5b4e6adf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T09:06:15.361834Z",
     "start_time": "2025-09-12T09:06:15.324011Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Configure an LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"qwen3-32b\",\n",
    "    temperature=0.5,\n",
    "    base_url=os.environ.get(\"COMPATIBLE_BASE_URL\"),\n",
    "    api_key=os.environ.get(\"COMPATIBLE_API_KEY\"),\n",
    "    streaming=True,\n",
    "    extra_body={\"enable_thinking\": False},\n",
    ")\n",
    "print(os.environ.get(\"COMPATIBLE_BASE_URL\"))\n",
    "print(os.getenv(\"COMPATIBLE_BASE_URL\"))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "e7be5117",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T09:06:43.667051Z",
     "start_time": "2025-09-12T09:06:36.302094Z"
    }
   },
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm.invoke([HumanMessage(content=\"你好，给我讲个笑话\")])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='当然可以！这里有一个轻松的小笑话：\\n\\n有一天，一只小鸭子走进一家药店，问药剂师：“你们有葡萄吗？”\\n\\n药剂师很困惑地说：“这里是药店，不是水果店。”\\n\\n第二天，小鸭子又来了，问：“你们有葡萄吗？”\\n\\n药剂师有点不耐烦了：“我不是说过多少次了吗？这里是药店，不是卖水果的！”\\n\\n第三天，小鸭子又来了，问：“你们有葡萄吗？”\\n\\n药剂师终于忍不住了，生气地说：“你再问一次，我就把你钉在墙上！”\\n\\n第四天，小鸭子来了，问：“你们有钉子吗？”\\n\\n药剂师说：“没有。”\\n\\n小鸭子点点头：“那你们有葡萄吗？”\\n\\n😄\\n\\n希望这个笑话能让你笑一笑！如果你喜欢某种类型的笑话（比如冷笑话、动物笑话、双关语等），我也可以专门讲那种类型的。', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen3-32b'}, id='run--00d5b4be-cec1-4d2d-a118-48af50c840fa-0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "4a0d6347",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T09:06:53.841085Z",
     "start_time": "2025-09-12T09:06:53.129988Z"
    }
   },
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "llm.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"你好，我叫李明！\"),\n",
    "        AIMessage(content=\"你好，李明！很高兴认识你。有什么我可以帮助你的吗？\"),\n",
    "        HumanMessage(content=\"我叫什么？\"),\n",
    "    ]\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你叫李明。如果还有其他问题，随时告诉我哦！', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen3-32b'}, id='run--05f6d539-7f1e-4298-8083-ded3bb57c29c-0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57b8b135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好！我无法直接知道你的名字，除非你告诉我。请问你的名字是什么呢？我很乐意在你知道的情况下帮你确认或记录下来哦！ 😊', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen3-32b'}, id='run--8181a0ae-9005-4dff-865d-7e59d479fa12-0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "llm.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"我叫什么？\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "id": "68d5aa25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T09:07:39.761289Z",
     "start_time": "2025-09-12T09:07:36.117933Z"
    }
   },
   "source": [
    "for chunk in llm.stream([HumanMessage(\"你好，我叫李明！\")]):\n",
    "    print(chunk.content, end=\"|\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|你好|，|李|明|！很高兴认识你|。我是Qwen|3，是阿里巴巴|最新推出的通义|千问大语言|模型。我能够|流畅地使用多种|语言进行交流，并|且在逻辑推理|、编程以及多|模态任务处理|方面都有出色的表现|。如果你有任何问题|或需要帮助，|随时告诉我，我会|尽力为你提供支持|。希望我们能|有愉快的交谈|！||"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "2d48fe02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T09:07:44.927045Z",
     "start_time": "2025-09-12T09:07:44.905390Z"
    }
   },
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"将下面的英文翻译成{language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "4aa6ecd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T09:07:52.031730Z",
     "start_time": "2025-09-12T09:07:51.585404Z"
    }
   },
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"中文\", \"text\": \"hi!\"})\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "fc1c75cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T09:07:57.601250Z",
     "start_time": "2025-09-12T09:07:56.326703Z"
    }
   },
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"日文\", \"text\": \"hi!\"})\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは！\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "caa2e5fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T09:07:59.750674Z",
     "start_time": "2025-09-12T09:07:59.350701Z"
    }
   },
   "source": [
    "translate_chain = prompt_template | llm\n",
    "\n",
    "response = translate_chain.invoke({\"language\": \"中文\", \"text\": \"hi!\"})\n",
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7423ff2a696e8e13"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
